# Multi-Site Price Tracker - Contexto del Proyecto

## ğŸ¯ PropÃ³sito

Construir un web scraper multi-sitio para rastrear precios de productos tech (GPUs, laptops, etc.) en mÃºltiples tiendas online (Amazon, PCComponentes).

**Parte de**: Portfolio de proyectos para demostrar competencias tÃ©cnicas a recruiters.

**Objetivos de aprendizaje:**
- Web scraping con Jsoup
- HTTP requests y rate limiting
- Retry logic y error handling
- CRUD avanzado con relaciones
- Scheduled jobs
- Strategy pattern (scraper por sitio)
- Spring Boot REST API

---

## ğŸ› ï¸ Stack tÃ©cnico

### Core
- **Java 17**
- **Spring Boot 3.2+**
- **Spring Data JPA** (Hibernate)
- **PostgreSQL 15**
- **Maven** (build tool)

### Web Scraping
- **Jsoup** (HTML parsing)
- **RestTemplate** (HTTP requests)
- **Guava RateLimiter** (rate limiting)

### Testing
- **JUnit 5**
- **Mockito**
- **Spring Boot Test**
- **TestContainers** (tests con PostgreSQL)

### Utilities
- **Lombok** (reduce boilerplate)
- **MapStruct** (DTO mapping)

### Infraestructura
- **Docker** (PostgreSQL en desarrollo)
- **Docker Compose**
- **GitHub Actions** (CI)

---

## ğŸ“ Estructura del proyecto

```
price-tracker/
â”œâ”€â”€ src/main/java/com/portfolio/pricetracker/
â”‚   â”œâ”€â”€ entity/
â”‚   â”‚   â”œâ”€â”€ Product.java
â”‚   â”‚   â”œâ”€â”€ ProductListing.java
â”‚   â”‚   â”œâ”€â”€ WebsiteSource.java
â”‚   â”‚   â”œâ”€â”€ PriceHistory.java
â”‚   â”‚   â”œâ”€â”€ ScrapingJob.java
â”‚   â”‚   â””â”€â”€ PriceAlert.java
â”‚   â”œâ”€â”€ repository/
â”‚   â”‚   â”œâ”€â”€ ProductRepository.java
â”‚   â”‚   â”œâ”€â”€ ProductListingRepository.java
â”‚   â”‚   â”œâ”€â”€ WebsiteSourceRepository.java
â”‚   â”‚   â”œâ”€â”€ PriceHistoryRepository.java
â”‚   â”‚   â””â”€â”€ ScrapingJobRepository.java
â”‚   â”œâ”€â”€ service/
â”‚   â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”‚   â”œâ”€â”€ SiteScraper.java (interface)
â”‚   â”‚   â”‚   â”œâ”€â”€ AmazonScraper.java
â”‚   â”‚   â”‚   â”œâ”€â”€ PCComponentesScraper.java
â”‚   â”‚   â”‚   â””â”€â”€ ScraperFactory.java
â”‚   â”‚   â”œâ”€â”€ ProductService.java
â”‚   â”‚   â”œâ”€â”€ ScrapingJobService.java
â”‚   â”‚   â””â”€â”€ PriceAlertService.java
â”‚   â”œâ”€â”€ controller/
â”‚   â”‚   â”œâ”€â”€ ProductController.java
â”‚   â”‚   â”œâ”€â”€ ScrapingJobController.java
â”‚   â”‚   â””â”€â”€ AnalyticsController.java
â”‚   â”œâ”€â”€ dto/
â”‚   â”‚   â”œâ”€â”€ ProductDTO.java
â”‚   â”‚   â”œâ”€â”€ ScrapedProductDTO.java
â”‚   â”‚   â””â”€â”€ PriceComparisonDTO.java
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ ScraperConfig.java
â”‚   â”‚   â””â”€â”€ SchedulingConfig.java
â”‚   â””â”€â”€ PriceTrackerApplication.java
â”œâ”€â”€ src/main/resources/
â”‚   â”œâ”€â”€ application.yml
â”‚   â”œâ”€â”€ application-dev.yml
â”‚   â””â”€â”€ db/migration/ (Flyway migrations)
â”œâ”€â”€ src/test/java/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ ci.yml
â”œâ”€â”€ .claude/
â”‚   â”œâ”€â”€ context.md
â”‚   â””â”€â”€ CURRENT_STATUS.md
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ architecture/
â”‚       â”œâ”€â”€ 001-scraper-strategy-pattern.md
â”‚       â”œâ”€â”€ 002-rate-limiting.md
â”‚       â””â”€â”€ 003-product-unification.md
â”œâ”€â”€ pom.xml
â””â”€â”€ README.md
```

---

## ğŸ’¾ Modelo de datos

### Entities y relaciones:

```java
// WebsiteSource (Amazon, PCComponentes, etc.)
@Entity
public class WebsiteSource {
  @Id @GeneratedValue
  private Long id;
  
  private String name;              // "Amazon ES"
  private String baseUrl;           // "https://www.amazon.es"
  
  @Enumerated(EnumType.STRING)
  private ScraperType scraperType;  // AMAZON, PCCOMPONENTES
  
  @Enumerated(EnumType.STRING)
  private SourceStatus status;      // ACTIVE, DISABLED, ERROR
  
  private LocalDateTime lastScrapedAt;
  private Integer successfulScrapes;
  private Integer failedScrapes;
  
  @CreationTimestamp
  private LocalDateTime createdAt;
  
  @UpdateTimestamp
  private LocalDateTime updatedAt;
}

// Product (producto unificado entre sitios)
@Entity
public class Product {
  @Id @GeneratedValue
  private Long id;
  
  @Column(nullable = false)
  private String name;              // "NVIDIA RTX 4070 SUPER"
  
  private String category;          // "gpu", "laptop", "monitor"
  private String imageUrl;
  
  @OneToMany(mappedBy = "product", cascade = CascadeType.ALL)
  private List<ProductListing> listings;
  
  @OneToMany(mappedBy = "product")
  private List<PriceHistory> priceHistory;
  
  @CreationTimestamp
  private LocalDateTime createdAt;
  
  @UpdateTimestamp
  private LocalDateTime updatedAt;
  
  @Column(nullable = true)
  private LocalDateTime deletedAt; // Soft delete
}

// ProductListing (producto en un sitio especÃ­fico)
@Entity
@Table(uniqueConstraints = @UniqueConstraint(
  columnNames = {"product_id", "source_id"}
))
public class ProductListing {
  @Id @GeneratedValue
  private Long id;
  
  @ManyToOne(fetch = FetchType.LAZY)
  @JoinColumn(name = "product_id", nullable = false)
  private Product product;
  
  @ManyToOne(fetch = FetchType.LAZY)
  @JoinColumn(name = "source_id", nullable = false)
  private WebsiteSource source;
  
  private String externalId;        // ID en el sitio externo
  
  @Column(nullable = false)
  private String url;
  
  private BigDecimal currentPrice;
  private String currency;          // "EUR"
  private Boolean inStock;
  
  private LocalDateTime lastScrapedAt;
  
  @OneToMany(mappedBy = "listing")
  private List<PriceHistory> priceHistory;
  
  @CreationTimestamp
  private LocalDateTime createdAt;
  
  @UpdateTimestamp
  private LocalDateTime updatedAt;
}

// PriceHistory (historial de precios)
@Entity
@Table(indexes = {
  @Index(name = "idx_listing_scraped", columnList = "listing_id,scraped_at")
})
public class PriceHistory {
  @Id @GeneratedValue
  private Long id;
  
  @ManyToOne(fetch = FetchType.LAZY)
  @JoinColumn(name = "listing_id", nullable = false)
  private ProductListing listing;
  
  @Column(nullable = false)
  private BigDecimal price;
  
  private Boolean inStock;
  
  @Column(nullable = false)
  private LocalDateTime scrapedAt;
}

// ScrapingJob (trabajo de scraping)
@Entity
public class ScrapingJob {
  @Id @GeneratedValue
  private Long id;
  
  @ManyToOne(fetch = FetchType.LAZY)
  @JoinColumn(name = "source_id")
  private WebsiteSource source;
  
  private String searchKeyword;     // "rtx 4070"
  private String category;          // "gpu"
  
  @Enumerated(EnumType.STRING)
  private JobStatus status;         // PENDING, RUNNING, COMPLETED, FAILED
  
  private Integer itemsFound;
  
  @Lob
  private String errorMessage;
  
  private LocalDateTime startedAt;
  private LocalDateTime completedAt;
  
  @CreationTimestamp
  private LocalDateTime createdAt;
}

// PriceAlert (alertas de precio)
@Entity
public class PriceAlert {
  @Id @GeneratedValue
  private Long id;
  
  @ManyToOne(fetch = FetchType.LAZY)
  private Product product;
  
  private String userEmail;
  private BigDecimal targetPrice;
  
  @Enumerated(EnumType.STRING)
  private AlertStatus status;       // ACTIVE, TRIGGERED, DISABLED
  
  private LocalDateTime triggeredAt;
  
  @CreationTimestamp
  private LocalDateTime createdAt;
}
```

---

## ğŸš€ API Endpoints

### 1. Website Sources
```
GET    /api/sources              # Listar sitios
POST   /api/sources              # AÃ±adir sitio
GET    /api/sources/{id}         # Ver sitio
PUT    /api/sources/{id}         # Actualizar
DELETE /api/sources/{id}         # Eliminar
GET    /api/sources/{id}/stats   # EstadÃ­sticas
```

### 2. Scraping Jobs
```
POST   /api/scraping/jobs           # Crear job
GET    /api/scraping/jobs           # Listar jobs
GET    /api/scraping/jobs/{id}      # Ver job
POST   /api/scraping/jobs/{id}/run  # Ejecutar
DELETE /api/scraping/jobs/{id}      # Cancelar
```

### 3. Products (CRUD + Filtros)
```
GET    /api/products                       # Listar
GET    /api/products?category=gpu          # Filtrar categorÃ­a
GET    /api/products?minPrice=500          # Filtrar precio
GET    /api/products?keyword=rtx           # Buscar
GET    /api/products/{id}                  # Ver producto
GET    /api/products/{id}/listings         # Ver en quÃ© sitios estÃ¡
GET    /api/products/{id}/best-price       # Mejor precio
GET    /api/products/{id}/price-history    # Historial
PUT    /api/products/{id}                  # Actualizar
DELETE /api/products/{id}                  # Soft delete
```

### 4. Analytics
```
GET    /api/analytics/price-drops          # Mayores bajadas
GET    /api/analytics/price-increases      # Mayores subidas
GET    /api/analytics/trending             # MÃ¡s scrapeados
GET    /api/analytics/cheapest-site        # Sitio mÃ¡s barato
GET    /api/compare?productId=1            # Comparar precios
```

### 5. Price Alerts (Opcional - Fase 7)
```
POST   /api/alerts        # Crear alerta
GET    /api/alerts        # Mis alertas
DELETE /api/alerts/{id}   # Eliminar
```

---

## ğŸ”§ Estrategia de Web Scraping

### Strategy Pattern:

```java
public interface SiteScraper {
  String getSiteName();
  ScraperType getScraperType();
  List<ScrapedProductDTO> scrape(String keyword, String category);
  ProductDetailsDTO scrapeDetails(String url);
}

@Service
public class AmazonScraper implements SiteScraper {
  
  private final RateLimiter rateLimiter = RateLimiter.create(2.0); // 2 req/sec
  
  @Override
  public List<ScrapedProductDTO> scrape(String keyword, String category) {
    rateLimiter.acquire();
    
    String url = buildSearchUrl(keyword, category);
    Document doc = Jsoup.connect(url)
      .userAgent("Mozilla/5.0...")
      .timeout(10000)
      .get();
    
    Elements items = doc.select(".s-result-item");
    
    return items.stream()
      .map(this::parseProduct)
      .filter(Objects::nonNull)
      .collect(Collectors.toList());
  }
  
  private ScrapedProductDTO parseProduct(Element item) {
    // Extraer nombre, precio, URL, imagen
    // Selectores especÃ­ficos de Amazon
  }
}

@Service
public class ScraperFactory {
  
  private final Map<ScraperType, SiteScraper> scrapers;
  
  public ScraperFactory(List<SiteScraper> scraperList) {
    this.scrapers = scraperList.stream()
      .collect(Collectors.toMap(
        SiteScraper::getScraperType,
        Function.identity()
      ));
  }
  
  public SiteScraper getScraper(ScraperType type) {
    SiteScraper scraper = scrapers.get(type);
    if (scraper == null) {
      throw new UnsupportedScraperException(type);
    }
    return scraper;
  }
}
```

### Rate Limiting:
- **Guava RateLimiter**: 2 requests/segundo por sitio
- Evita IP bans
- Configurable por sitio en `application.yml`

### Retry Logic:
```java
@Retryable(
  value = {IOException.class, HttpStatusException.class},
  maxAttempts = 3,
  backoff = @Backoff(delay = 1000, multiplier = 2)
)
public Document fetchPage(String url) throws IOException {
  return Jsoup.connect(url).get();
}
```

### Error Handling:
- Timeout: 10 segundos
- User-Agent rotation
- Logging de errores
- Graceful degradation

---

## ğŸ§ª Estrategia de testing

### Tests unitarios:
```java
@Test
void testAmazonScraper_ParsesProductCorrectly() {
  String html = loadHtmlFixture("amazon_product.html");
  Document doc = Jsoup.parse(html);
  
  ScrapedProductDTO product = amazonScraper.parseProduct(doc);
  
  assertThat(product.getName()).contains("RTX 4070");
  assertThat(product.getPrice()).isGreaterThan(BigDecimal.ZERO);
}
```

### Tests de integraciÃ³n:
```java
@SpringBootTest
@Testcontainers
class ProductServiceIntegrationTest {
  
  @Container
  static PostgreSQLContainer<?> postgres = new PostgreSQLContainer<>("postgres:15");
  
  @Test
  void testCreateProduct_SavesSuccessfully() {
    ProductDTO dto = new ProductDTO("RTX 4070", "gpu");
    Product saved = productService.create(dto);
    
    assertThat(saved.getId()).isNotNull();
  }
}
```

### Cobertura objetivo:
- **>80%** en services y scrapers
- **>70%** en controllers
- Edge cases cubiertos

---

## ğŸ” Decisiones arquitectÃ³nicas a documentar

### 1. Strategy Pattern para scrapers
**Problema:** Cada sitio tiene HTML diferente
**DecisiÃ³n:** Interface SiteScraper + implementaciÃ³n por sitio
**Trade-off:** MÃ¡s clases vs extensibilidad

### 2. Product Unification
**Problema:** Mismo producto en varios sitios
**DecisiÃ³n:** Entity Product + ProductListing (relaciÃ³n 1-N)
**Trade-off:** Complejidad vs normalizaciÃ³n

### 3. Rate Limiting
**Problema:** Evitar IP bans
**DecisiÃ³n:** Guava RateLimiter (2 req/sec)
**Trade-off:** Velocidad vs seguridad

### 4. Jsoup vs Selenium
**Problema:** CÃ³mo parsear HTML
**DecisiÃ³n:** Jsoup (ligero, no JS rendering)
**Trade-off:** Simplicidad vs sitios con JS

### 5. Scheduled Jobs
**Problema:** Scraping automÃ¡tico diario
**DecisiÃ³n:** Spring @Scheduled (cron)
**Trade-off:** Built-in vs Quartz (mÃ¡s potente)

---

## ğŸ“š Convenciones del proyecto

### Java/Spring Boot
- Java 17 features (records, switch expressions)
- Lombok para reducir boilerplate
- MapStruct para DTO mapping
- Constructor injection (no @Autowired en campos)

### Git Workflow
- Conventional Commits: `feat:`, `fix:`, `docs:`, `test:`, `refactor:`
- Branch naming: `feat/feature-name`, `fix/bug-name`
- PRs descriptivos (sin fake reviews)

### Testing
- AAA pattern (Arrange, Act, Assert)
- Test names: `should_ExpectedBehavior_When_StateUnderTest`
- Fixtures en `src/test/resources/fixtures/`

### Docker
- **Desarrollo:** PostgreSQL en Docker, app local
- **CI/CD:** Todo en Docker
- docker-compose.yml para desarrollo
- Dockerfile multi-stage para producciÃ³n

---

## ğŸªŸ Comandos Ãºtiles

```bash
# Desarrollo
./mvnw spring-boot:run              # Correr app
./mvnw test                          # Tests
./mvnw clean install                 # Build completo

# Docker
docker-compose up -d                 # PostgreSQL
docker-compose logs -f postgres      # Ver logs
docker-compose down                  # Detener

# Database
docker exec -it price-tracker-db psql -U pricetracker -d pricetracker

# Testing
./mvnw test                          # Todos los tests
./mvnw test -Dtest=ProductServiceTest  # Test especÃ­fico
./mvnw verify                        # Tests + integration tests
```

---

## âš ï¸ Consideraciones legales/Ã©ticas

### Web Scraping:
- âœ… Respetar `robots.txt`
- âœ… Rate limiting agresivo (2 req/sec)
- âœ… User-Agent honesto
- âœ… Solo para fines educativos
- âœ… Disclaimer en README

### README Disclaimer:
```
âš ï¸ **Educational Purpose Only**

This project is built for learning purposes to demonstrate web scraping,
Spring Boot, and backend development skills. It should NOT be used for
commercial purposes without proper authorization from the scraped websites.

Always respect robots.txt and implement appropriate rate limiting.
```

---

## ğŸ“ Objetivos de aprendizaje

Este proyecto demuestra a recruiters:

1. **Web Scraping**: Jsoup, HTTP requests, HTML parsing
2. **Spring Boot**: REST API, JPA, scheduled jobs
3. **Design Patterns**: Strategy pattern, Factory
4. **Rate Limiting**: Guava RateLimiter, evitar bans
5. **Retry Logic**: Resilience4j, exponential backoff
6. **CRUD avanzado**: Relaciones 1-N, filtros, soft deletes
7. **Testing**: JUnit, Mockito, TestContainers
8. **Docker**: ContainerizaciÃ³n, docker-compose
9. **CI/CD**: GitHub Actions
10. **Git Workflow**: Feature branches, PRs, conventional commits
