# ADR-004: Site Selection After Cloudflare Blocking

**Status:** Accepted
**Date:** 2026-02
**Phase:** 4 (Second Scraper)

---

## Context

Phase 4 planned PCComponentes as the second site to scrape. During development it was discovered that PCComponentes blocks non-browser HTTP clients with Cloudflare's **Interactive Challenge** (`cType: interactive`).

History of the investigation:

1. **Attempt 1**: Direct Jsoup → Cloudflare blocks it (the HTML contains a JS challenge instead of data)
2. **Attempt 2**: Discover the site's internal JSON API (`/api/articles/search`) and access it with RestTemplate → also blocked with 403 + Cloudflare challenge
3. **Diagnosis**: The response error confirms the block type:
   ```
   ERROR: HttpClientErrorException$Forbidden - 403 Forbidden
   response: "cType: 'interactive'" ... "Enable JavaScript and cookies to continue"
   ```

Cloudflare's Interactive Challenge requires real JavaScript execution and cryptographic cookie resolution. No standard HTTP client (Jsoup, RestTemplate, HttpClient) can solve it.

---

## Problem

How to proceed with the second scraper given that PCComponentes blocks all HTTP clients?

---

## Options considered

### Option 1: Selenium/Playwright for PCComponentes

Use a headless browser (Chrome/Firefox) that executes JavaScript and resolves the challenge automatically.

**Pros:** Technically complete solution. PCComponentes would be functional.
**Cons:**
- Requires ChromeDriver or Playwright binaries (>100MB)
- Much higher CPU/memory usage than Jsoup
- Requests take 3-5 seconds instead of ~200ms
- Cloudflare may still detect headless browsers and block them
- Adds significant operational complexity without adding new value to the Strategy Pattern (already demonstrated with Amazon)

### Option 2: Scraping API (ScraperAPI, BrightData)

Use a proxy service that handles the Cloudflare bypass. Requests route through their infrastructure.

**Pros:** No architectural changes needed. Only the request URL changes.
**Cons:** Dependency on a paid external service (though with a free tier). Adds extra latency. For an educational portfolio, adds configuration complexity without clear pedagogical value.

### Option 3: Switch from PCComponentes to MediaMarkt and document the block ✅

Replace PCComponentes with MediaMarkt ES, which:
- Does not use Cloudflare Interactive Challenge
- Although it is a SPA (React), it embeds structured data as **JSON-LD** (`schema.org/ItemList`) that Jsoup can extract directly without executing JS

Document the PCComponentes block in the README as a conscious architectural decision.

**Pros:**
- Functional scraper using the same architecture (Jsoup)
- Demonstrates ability to adapt to real-world obstacles
- JSON-LD is more robust than CSS selectors (does not change with UI redesigns)
- The PCComponentes blocking is a real industry issue worth documenting

**Cons:** PCComponentes is not in the final portfolio as a functional site.

### Option 4: Mock/simulation of PCComponentes

Implement a scraper that returns hardcoded fake data to demonstrate the pattern.

**Pros:** No blocking, pattern demonstrated.
**Cons:** Dishonest in a portfolio project. Does not demonstrate real scraping.

---

## Decision

**Option 3: MediaMarkt ES with JSON-LD.**

The primary criterion was maximising portfolio value: demonstrate that something real works (real scraping, against a real site, with real data) and honestly document the Cloudflare obstacle with its technical implications.

---

## MediaMarkt scraping technique

MediaMarkt uses React (SPA), so standard HTML does not contain the data. However, the page includes a `<script type="application/ld+json">` with the Schema.org `ItemList` schema:

```json
{
  "@context": "https://schema.org",
  "@type": "ItemList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position": 1,
      "item": {
        "@type": "Product",
        "name": "ASUS TUF Gaming RTX 4070 SUPER",
        "offers": { "price": 619.00, "priceCurrency": "EUR" },
        "url": "https://www.mediamarkt.es/es/product/...",
        "image": "https://assets.mmsrg.com/..."
      }
    }
  ]
}
```

Jsoup extracts the `script[type=application/ld+json]` tag, Jackson parses the JSON, and the structure `ListItem → item` is traversed.

**Advantage over CSS selectors**: JSON-LD is semantic and stable. Class names generated by styled-components change on every deploy. JSON-LD rarely changes because it serves SEO purposes.

---

## Consequences

### Positive
- Two functional, real scrapers in the portfolio
- Demonstrates ability to solve unforeseen problems in web scraping
- MediaMarkt + JSON-LD is a more robust technique than CSS selectors for SPAs
- Documenting the Cloudflare blocking is valuable as a learning

### Negative
- PCComponentes is not supported. Adding it in the future would require evaluating Playwright or a scraping proxy

---

## Lessons learned

1. **Internal APIs are not public**: Just because the browser can access `/api/articles/search` does not mean an HTTP client can. Cloudflare protects both HTML and XHR requests.

2. **JSON-LD as a data source**: Modern sites using SPAs often include JSON-LD for SEO. It is a legitimate and stable data extraction technique.

3. **Document the obstacles**: In a portfolio, explaining why something does not work (and showing you understand the problem) is as valuable as showing it working.

---

## References

- [Cloudflare Bot Management](https://www.cloudflare.com/products/bot-management/)
- [Schema.org ItemList](https://schema.org/ItemList)
- [JSON-LD Specification](https://json-ld.org/)
- See Learning 001 for Jsoup techniques
- `MediaMarktScraper.java`, `README.md`
